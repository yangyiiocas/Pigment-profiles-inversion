{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac11e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12be0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"1 read SeaBASS HPLC\", \"1 read MAREDAT\",\"1 read Kramer sorted\"]\n",
    "\n",
    "dates_file, lons_file, lats_file, depths_file, data_file = {}, {}, {}, {}, {}\n",
    "for name in files:\n",
    "    with open(\"../0 save inner data/\"+name+\".pkl\",'rb') as f:\n",
    "        dates_file[name], lons_file[name], lats_file[name], depths_file[name], data_file[name] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066ad919",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = np.array([])\n",
    "for item in files: source = np.append(source, [item.split(\"read \")[1]]*len(lats_file[item]))\n",
    "    \n",
    "lats = np.array([])\n",
    "for item in lats_file: lats = np.append(lats, lats_file[item])\n",
    "    \n",
    "lons = np.array([])\n",
    "for item in lons_file: lons = np.append(lons, lons_file[item])\n",
    "\n",
    "depths = np.array([])\n",
    "for item in depths_file: depths = np.append(depths, depths_file[item])\n",
    "\n",
    "dates = np.array([])\n",
    "for item in dates_file: dates = np.append(dates, dates_file[item])\n",
    "\n",
    "# data = {var:np.array([]) for var in [item for file in data_file for item in data_file[file]]}\n",
    "variables = [\"fuco\",\"perid\",\"hex_fuco\",\"but_fuco\",\"allo\",\"tchl_b\",\"zea\",\"tchl_a\",\"dv_chl_a\"]\n",
    "data = {var:[] for var in variables}\n",
    "for var in data:\n",
    "    for file in data_file:\n",
    "        if var in data_file[file]:\n",
    "            data[var] = np.append(data[var], data_file[file][var])\n",
    "        else:\n",
    "            data[var] = np.append(data[var], np.nan*np.zeros_like(lons_file[file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85b2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fuco', 'perid', 'hex_fuco', 'but_fuco', 'allo', 'tchl_b', 'zea', 'tchl_a', 'dv_chl_a']\n"
     ]
    }
   ],
   "source": [
    "print(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226e8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../0 save inner data/1 read all HPLC.pkl\", 'wb') as f:\n",
    "    pickle.dump([source, dates, lons, lats, depths, data], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ea8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../0 save data/read all HPLC.txt\",'w') as f:\n",
    "    write_str = \"source\"+\"\\t\"+\"datetime\"+\"\\t\"+\"lat\"+\"\\t\"+\"lon\"+\"\\t\"+\"depth\"+\"\\t\"\n",
    "    for var in data:write_str = write_str+var+\"\\t\"\n",
    "    f.write(write_str+\"\\n\")\n",
    "    for i in range(len(lats)):\n",
    "        write_str = source[i]+str(dates[i])+\"\\t\"+str(lats[i])+\"\\t\"+str(lons[i])+\"\\t\"+str(depths[i])+\"\\t\"\n",
    "        for var in data: write_str = (write_str+str(data[var][i])+\"\\t\") if data[var][i]==data[var][i] else (write_str+str(-999)+\"\\t\")\n",
    "        f.write(write_str+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
